{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4dd5952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Qwen3VLForConditionalGeneration, AutoProcessor\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "SLURM_PATH = '/home/yandex/MLWG2025/amitr5'\n",
    "CACHE_DIR = f'{SLURM_PATH}/tmp/hf_cache'  # Changed to /tmp to avoid quota issues\n",
    "\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "if SLURM_PATH in os.getcwd():\n",
    "    os.environ[\"PIP_PATH\"] = f\"{SLURM_PATH}/BaryGNN/anaconda3/envs/conf/bin/pip\"\n",
    "    os.environ[\"TEMP_DIR\"] = CACHE_DIR\n",
    "    os.environ[\"HF_HOME\"] = CACHE_DIR\n",
    "    os.environ[\"TRANSFORMERS_CACHE\"] = CACHE_DIR\n",
    "    os.environ[\"HF_DATASETS_CACHE\"] = CACHE_DIR\n",
    "    os.environ[\"HF_HUB_CACHE\"] = CACHE_DIR\n",
    "    os.environ[\"TMPDIR\"] = CACHE_DIR\n",
    "    # os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea594029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5f87240707b4fee8c3ab9aa958c071a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee648f3e3e4c48fdbca1b8ada5609b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import Dict, Any\n",
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, T5Tokenizer\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('./Mind2Web/src')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport action_prediction.dataloader, data_utils.dom_utils\n",
    "\n",
    "from action_prediction.dataloader import MultiChoiceDataset, get_data_split\n",
    "split_file = \"test_task\"  # or \"test_task\" or \"test_website\"\n",
    "# candidate_results = pickle.load(open(f\"{SLURM_PATH}/results/mind2web_{split_file}_candidates.pkl\", \"rb\"))\n",
    "candidate_results = pd.read_pickle(f\"candidates/scores_{split_file}.pkl\")\n",
    "flattened = get_data_split(\n",
    "    data_dir=\"osunlp/Multimodal-Mind2Web\",\n",
    "    split_file=split_file,\n",
    "    candidate_results=candidate_results,\n",
    "    cache_dir=CACHE_DIR\n",
    ")\n",
    "\n",
    "def tensorize_item(item: Dict[str, Any], device: str):\n",
    "    \"\"\"\n",
    "    Convert the model_input dict returned by MultiChoiceDataset.__getitem__\n",
    "    (lists of ints) into tensors appropriate for model.generate.\n",
    "    \"\"\"\n",
    "    input_ids = torch.LongTensor(item[\"input_ids\"]).unsqueeze(0).to(device)\n",
    "    attention_mask = torch.LongTensor(item[\"attention_mask\"]).unsqueeze(0).to(device)\n",
    "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"osunlp/MindAct_ActionPrediction_flan-t5-xl\" #\"Qwen/Qwen-3.5-VL-Base\"\n",
    "\n",
    "# Load tokenizer and model\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False, cache_dir=CACHE_DIR)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-xl\", cache_dir=CACHE_DIR)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, cache_dir=CACHE_DIR)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Construct MultiChoiceDataset like evaluate.py does.\n",
    "dataset = MultiChoiceDataset(\n",
    "        flattened,\n",
    "        tokenizer,\n",
    "        neg_ratio=0,\n",
    "        num_candidates=5,\n",
    "        max_context_len=512,\n",
    "        # mode=\"generation\",  # use generation formatting\n",
    "        mode=\"multichoice\",  # use multichoice formatting\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "427e7105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "978129a3201147a3a52674490776ab0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a99276d8fc4298aa0530b9dda12884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits: ['train', 'test_domain', 'test_task', 'test_website']\n",
      "Number of samples in test_domain: 4060\n",
      "Number of samples in test_task: 1339\n",
      "Number of samples in test_website: 1019\n",
      "Total number of test samples: 6418\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"osunlp/Multimodal-Mind2Web\", cache_dir=CACHE_DIR)\n",
    "\n",
    "print(\"Dataset splits:\", list(ds.keys()))\n",
    "# Access the test splits\n",
    "test_domain_ds = ds['test_domain']\n",
    "test_task_ds = ds['test_task']\n",
    "test_website_ds = ds['test_website']\n",
    "\n",
    "print(f\"Number of samples in test_domain: {len(test_domain_ds)}\")\n",
    "print(f\"Number of samples in test_task: {len(test_task_ds)}\")\n",
    "print(f\"Number of samples in test_website: {len(test_website_ds)}\")\n",
    "print(\"Total number of test samples:\", len(test_domain_ds) + len(test_task_ds) + len(test_website_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d9fe52ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Sample 0 --------------------\n",
      "annotation_id=91695df8-f256-47c9-8c37-06e8d0fc758f, generated=B\n",
      "-------------------- Sample 1 --------------------\n",
      "annotation_id=91695df8-f256-47c9-8c37-06e8d0fc758f, generated=D\n",
      "-------------------- Sample 1 --------------------\n",
      "annotation_id=91695df8-f256-47c9-8c37-06e8d0fc758f, generated=D\n",
      "-------------------- Sample 2 --------------------\n",
      "annotation_id=91695df8-f256-47c9-8c37-06e8d0fc758f, generated=C\n",
      "-------------------- Sample 2 --------------------\n",
      "annotation_id=91695df8-f256-47c9-8c37-06e8d0fc758f, generated=C\n",
      "-------------------- Sample 3 --------------------\n",
      "annotation_id=91695df8-f256-47c9-8c37-06e8d0fc758f, generated=C\n",
      "-------------------- Sample 3 --------------------\n",
      "annotation_id=91695df8-f256-47c9-8c37-06e8d0fc758f, generated=C\n",
      "-------------------- Sample 4 --------------------\n",
      "annotation_id=91695df8-f256-47c9-8c37-06e8d0fc758f, generated=F\n",
      "-------------------- Sample 4 --------------------\n",
      "annotation_id=91695df8-f256-47c9-8c37-06e8d0fc758f, generated=F\n",
      "-------------------- Sample 5 --------------------\n",
      "annotation_id=91695df8-f256-47c9-8c37-06e8d0fc758f, generated=C\n",
      "-------------------- Sample 5 --------------------\n",
      "annotation_id=91695df8-f256-47c9-8c37-06e8d0fc758f, generated=C\n",
      "-------------------- Sample 6 --------------------\n",
      "annotation_id=91695df8-f256-47c9-8c37-06e8d0fc758f, generated=C\n",
      "-------------------- Sample 6 --------------------\n",
      "annotation_id=91695df8-f256-47c9-8c37-06e8d0fc758f, generated=C\n",
      "-------------------- Sample 7 --------------------\n",
      "annotation_id=91695df8-f256-47c9-8c37-06e8d0fc758f, generated=C\n",
      "-------------------- Sample 7 --------------------\n",
      "annotation_id=91695df8-f256-47c9-8c37-06e8d0fc758f, generated=C\n",
      "-------------------- Sample 8 --------------------\n",
      "annotation_id=91695df8-f256-47c9-8c37-06e8d0fc758f, generated=C\n",
      "-------------------- Sample 8 --------------------\n",
      "annotation_id=91695df8-f256-47c9-8c37-06e8d0fc758f, generated=C\n",
      "-------------------- Sample 9 --------------------\n",
      "annotation_id=91695df8-f256-47c9-8c37-06e8d0fc758f, generated=B\n",
      "Processed 10 samples total\n",
      "------------------------------------------------------------\n",
      "-------------------- Sample 9 --------------------\n",
      "annotation_id=91695df8-f256-47c9-8c37-06e8d0fc758f, generated=B\n",
      "Processed 10 samples total\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "choices_to_token_ids = dataset.choices_token_ids_mapping()\n",
    "outputs = []\n",
    "all_scores = []  # Store scores for each sample\n",
    "\n",
    "# The dataset length equals len(flattened)*10, and __getitem__ expands each original\n",
    "# sample into multiple training examples. To pick distinct original examples we\n",
    "# sample every 10th item (0, 10, 20, ...).\n",
    "num_samples = 10  # number of original examples to generate for\n",
    "max_new_tokens = 1#50\n",
    "max_examples = min(num_samples, len(dataset.data))\n",
    "for i in range(max_examples):\n",
    "        idx = i * 10 \n",
    "        if idx >= len(dataset):\n",
    "            # fallback: sample last available indices if necessary\n",
    "            idx = min(idx, len(dataset) - 1)\n",
    "        item = dataset[idx]  # this is a dict with lists: input_ids, attention_mask, labels\n",
    "        model_input = tensorize_item(item, device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model.generate(\n",
    "                **model_input,\n",
    "                eos_token_id=model.config.eos_token_id,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                return_dict_in_generate=True,\n",
    "                output_scores=True,\n",
    "            )\n",
    "\n",
    "        decoded = tokenizer.batch_decode(out[\"sequences\"], skip_special_tokens=True)[0]\n",
    "        labels_tokens = item.get(\"labels\")\n",
    "       \n",
    "        # Calculate choice probabilities\n",
    "        logits = out[\"scores\"][0][0]\n",
    "        all_probs = F.softmax(logits, dim=-1)\n",
    "        probs = all_probs[list(choices_to_token_ids.values())]\n",
    "        choices_probs = dict(zip(choices_to_token_ids.keys(), probs.cpu().tolist()))\n",
    "\n",
    "        outputs.append(\n",
    "            {\n",
    "                \"index\": i,\n",
    "                \"dataset_index\": idx,\n",
    "                \"annotation_id\": dataset.data[i].get(\"annotation_id\"),\n",
    "                \"action_uid\": dataset.data[i].get(\"action_uid\"),\n",
    "                \"generated\": decoded,\n",
    "                # include labels/tokenized labels for reference (if available)\n",
    "                \"labels_tokens\": item.get(\"labels\"),\n",
    "                \"choices_probs\": choices_probs,\n",
    "                \"score\":1 - choices_probs.get(decoded, 0)\n",
    "            }\n",
    "        )\n",
    "        print(f\"{'-'*20} Sample {i} {'-'*20}\")\n",
    "        print(f\"annotation_id={dataset.data[i].get('annotation_id')}, generated={decoded}\")\n",
    "        \n",
    "        \n",
    "print(f\"Processed {len(outputs)} samples total\")\n",
    "print(\"-\" * 60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c610b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best option: 0.8456717729568481\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "options = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"]\n",
    "\n",
    "\n",
    "\n",
    "def temp2():\n",
    "    option_logits = {opt: logits[token_id].item() for opt, token_id in choices_to_token_ids.items()}\n",
    "\n",
    "# print(\"\\nRaw logits for each option:\")\n",
    "   \n",
    "    # for opt, logit in option_logits.items():\n",
    "        # normalized_prob = all_probs[choices_to_token_ids[opt]]\n",
    "        # marker = \" <-- GENERATED\" if opt == generated_token.strip() else \"\"\n",
    "        # print(f\"  {opt}: logit={logit:.4f}, normalized_prob={normalized_prob:.6f}{marker}\")\n",
    "\n",
    "    # Find the option with highest logit\n",
    "    best_option = max(choices_probs)\n",
    "    print(f\"Best option: {best_option}\")\n",
    "\n",
    "temp2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7a5d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5075e-01, 8.4567e-01, 1.4490e-03, 1.0129e-03, 2.1158e-04, 4.7099e-04])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f3dd7f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177 μs ± 17.7 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def temp():  \n",
    "    # Let's check what the model would generate if we manually take argmax\n",
    "    all_probs = F.softmax(logits, dim=-1)\n",
    "    top5_probs, top5_ids = torch.topk(all_probs, k=5)\n",
    "    # print(f\"\\nTop 10 tokens by probability:\")\n",
    "    return top5_ids, top5_probs\n",
    "    # for prob, token_id in zip(top5_probs, top5_ids):\n",
    "        # token = tokenizer.decode([token_id.item()])\n",
    "        # print(f\"  {token!r} (ID: {token_id.item()}): {prob.item():.6f} | logit: {logits[token_id].item():.4f} | {token_id}\")\n",
    "\n",
    "    # Check if generated token is in top predictions\n",
    "    # if generated_token_id in top5_ids:\n",
    "    #     rank = (top5_ids == generated_token_id).nonzero(as_tuple=True)[0].item() + 1\n",
    "    #     print(f\"\\n✓ Generated token '{generated_token.strip()}' is rank #{rank} in logits\")\n",
    "    # else:\n",
    "    #     print(f\"\\n⚠️  Generated token '{generated_token.strip()}' is NOT in top 10!\")\n",
    "\n",
    "%timeit temp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa98791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 71, 'B': 272, 'C': 205, 'D': 309, 'E': 262, 'F': 377}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6f78cf5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([272,  71, 205, 309, 377])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%aimport action_prediction.dataloader, data_utils.dom_utils\n",
    "options = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"]\n",
    "all_probs = F.softmax(logits, dim=-1)\n",
    "top5_probs, top5_ids = torch.topk(all_probs, k=5)\n",
    "top5_ids\n",
    "# x=dataset[11]\n",
    "# dataset.data[0]\n",
    "# sum([len(dataset.data[i][\"pos_candidates\"]) for i in range(len(dataset.data))])\n",
    "#TODO:\n",
    "# Figure out action representation formatting for multichoice vs generation modes\n",
    "# Understand if getting a closed answer (e.g., \"B\") is enough for full action representation (e.g., Action:CLICK)\n",
    "# Decide if output should be with \\n or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a72b10df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"original_op\": \"CLICK\", \"value\": \"\", \"op\": \"CLICK\"}'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data[0].keys()\n",
    "x=dataset.data[14][\"operation\"]\n",
    "x\n",
    "# len(dataset.data[0][\"action_reprs\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2edcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import argparse\n",
    "import json\n",
    "import pathlib\n",
    "import sys\n",
    "from typing import Any, Dict\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# Import the repository's dataset utilities\n",
    "from action_prediction.dataloader import MultiChoiceDataset, get_data_split  # type: ignore\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--model-name\", default=\"google/flan-t5-base\")\n",
    "    parser.add_argument(\"--data-dir\", required=True, help=\"data dir or dataset script used by get_data_split\")\n",
    "    parser.add_argument(\"--split-file\", required=True, help=\"path to split json file or list accepted by get_data_split\")\n",
    "    parser.add_argument(\"--num-samples\", type=int, default=10)\n",
    "    parser.add_argument(\"--device\", default=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    parser.add_argument(\"--out\", default=\"multichoice_generations.json\")\n",
    "    parser.add_argument(\"--max-new-tokens\", type=int, default=50)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    outputs = generate_with_dataset(\n",
    "        model_name=args.model_name,\n",
    "        data_dir=args.data_dir,\n",
    "        split_file=args.split_file,\n",
    "        num_samples=args.num_samples,\n",
    "        device=args.device,\n",
    "        max_new_tokens=args.max_new_tokens,\n",
    "    )\n",
    "\n",
    "    with open(args.out, \"w\") as f:\n",
    "        json.dump(outputs, f, indent=2)\n",
    "    print(f\"Wrote {len(outputs)} generations to {args.out}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b225954e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'490dc61c-873d-47b6-9050-369cd18e1253_f68804d6-48de-445b-b201-c63d35b8683c'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "scores = pd.read_pickle('scores_all_data.pkl')\n",
    "s = list(scores[\"scores\"].keys())[0]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a573da3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action UID: 490dc61c-873d-47b6-9050-369cd18e1253\n",
      "\n",
      "Found 0 matching rows in test_ds:\n",
      "Empty DataFrame\n",
      "Columns: [action_uid, raw_html, cleaned_html, operation, pos_candidates, neg_candidates, website, domain, subdomain, annotation_id, confirmed_task, screenshot, action_reprs, target_action_index, target_action_reprs]\n",
      "Index: []\n",
      "\n",
      "Found 0 matching rows in test_ds:\n",
      "Empty DataFrame\n",
      "Columns: [action_uid, raw_html, cleaned_html, operation, pos_candidates, neg_candidates, website, domain, subdomain, annotation_id, confirmed_task, screenshot, action_reprs, target_action_index, target_action_reprs]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Extract action_uid from the scores key\n",
    "action_uid = s.split('_')[0]\n",
    "print(f\"Action UID: {action_uid}\")\n",
    "\n",
    "# Search for this action_uid in test_ds\n",
    "test_df = test_ds.to_pandas()\n",
    "matching_rows = test_df[test_df['action_uid'] == action_uid]\n",
    "print(f\"\\nFound {len(matching_rows)} matching rows in test_ds:\")\n",
    "print(matching_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeceb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract action_uid from the scores key\n",
    "action_uid = s.split('_')[1]\n",
    "print(f\"Action UID: {action_uid}\")\n",
    "matching_rows = test_df[test_df['action_uid'] == action_uid]\n",
    "print(f\"\\nFound {len(matching_rows)} matching rows in test_ds:\")\n",
    "print(matching_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d206a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action_uid</th>\n",
       "      <th>raw_html</th>\n",
       "      <th>cleaned_html</th>\n",
       "      <th>operation</th>\n",
       "      <th>pos_candidates</th>\n",
       "      <th>neg_candidates</th>\n",
       "      <th>website</th>\n",
       "      <th>domain</th>\n",
       "      <th>subdomain</th>\n",
       "      <th>annotation_id</th>\n",
       "      <th>confirmed_task</th>\n",
       "      <th>screenshot</th>\n",
       "      <th>action_reprs</th>\n",
       "      <th>target_action_index</th>\n",
       "      <th>target_action_reprs</th>\n",
       "      <th>action_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6c7a7082-2897-41c7-9688-4b0f3d778cdb</td>\n",
       "      <td>&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.0 Tr...</td>\n",
       "      <td>&lt;html backend_node_id=\"208\"&gt;\\n  &lt;body backend_...</td>\n",
       "      <td>{\"original_op\": \"CLICK\", \"value\": \"\", \"op\": \"C...</td>\n",
       "      <td>[{\"tag\": \"li\", \"attributes\": \"{\\\"backend_node_...</td>\n",
       "      <td>[{\"tag\": \"div\", \"attributes\": \"{\\\"backend_node...</td>\n",
       "      <td>united</td>\n",
       "      <td>Travel</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>401c4e6f-6b0b-47b4-8157-92d7ca468bbc</td>\n",
       "      <td>rent a car in Brooklyn - Central, NY on from A...</td>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>[[heading]  CAR -&gt; CLICK, [combobox]  Enter pi...</td>\n",
       "      <td>0</td>\n",
       "      <td>[heading]  CAR -&gt; CLICK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b64c2417-c44e-46c4-bb0b-ff1775e7da29</td>\n",
       "      <td>&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.0 Tr...</td>\n",
       "      <td>&lt;html backend_node_id=\"10021\"&gt;\\n  &lt;body backen...</td>\n",
       "      <td>{\"original_op\": \"TYPE\", \"value\": \"Brooklyn Cen...</td>\n",
       "      <td>[{\"tag\": \"input\", \"attributes\": \"{\\\"backend_no...</td>\n",
       "      <td>[{\"tag\": \"div\", \"attributes\": \"{\\\"backend_node...</td>\n",
       "      <td>united</td>\n",
       "      <td>Travel</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>401c4e6f-6b0b-47b4-8157-92d7ca468bbc</td>\n",
       "      <td>rent a car in Brooklyn - Central, NY on from A...</td>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>[[heading]  CAR -&gt; CLICK, [combobox]  Enter pi...</td>\n",
       "      <td>1</td>\n",
       "      <td>[combobox]  Enter pick up city, airport name, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dad6690b-9b3e-4395-bd06-9aa065bf4027</td>\n",
       "      <td>&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.0 Tr...</td>\n",
       "      <td>&lt;html backend_node_id=\"20041\"&gt;\\n  &lt;body backen...</td>\n",
       "      <td>{\"original_op\": \"CLICK\", \"value\": \"\", \"op\": \"C...</td>\n",
       "      <td>[{\"tag\": \"button\", \"attributes\": \"{\\\"backend_n...</td>\n",
       "      <td>[{\"tag\": \"div\", \"attributes\": \"{\\\"backend_node...</td>\n",
       "      <td>united</td>\n",
       "      <td>Travel</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>401c4e6f-6b0b-47b4-8157-92d7ca468bbc</td>\n",
       "      <td>rent a car in Brooklyn - Central, NY on from A...</td>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>[[heading]  CAR -&gt; CLICK, [combobox]  Enter pi...</td>\n",
       "      <td>2</td>\n",
       "      <td>[div]  Brooklyn - Central (New York), US -&gt; CLICK</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e0fd3f28-3f04-455d-8bde-a480f0ec1b0a</td>\n",
       "      <td>&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.0 Tr...</td>\n",
       "      <td>&lt;html backend_node_id=\"30061\"&gt;\\n  &lt;body backen...</td>\n",
       "      <td>{\"original_op\": \"CLICK\", \"value\": \"\", \"op\": \"C...</td>\n",
       "      <td>[{\"tag\": \"input\", \"attributes\": \"{\\\"backend_no...</td>\n",
       "      <td>[{\"tag\": \"div\", \"attributes\": \"{\\\"backend_node...</td>\n",
       "      <td>united</td>\n",
       "      <td>Travel</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>401c4e6f-6b0b-47b4-8157-92d7ca468bbc</td>\n",
       "      <td>rent a car in Brooklyn - Central, NY on from A...</td>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>[[heading]  CAR -&gt; CLICK, [combobox]  Enter pi...</td>\n",
       "      <td>3</td>\n",
       "      <td>[textbox]  Pickup -&gt; CLICK</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4762d735-9dc2-4717-ae8b-baab0b3446e5</td>\n",
       "      <td>&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.0 Tr...</td>\n",
       "      <td>&lt;html backend_node_id=\"40453\"&gt;\\n  &lt;body backen...</td>\n",
       "      <td>{\"original_op\": \"CLICK\", \"value\": \"\", \"op\": \"C...</td>\n",
       "      <td>[{\"tag\": \"td\", \"attributes\": \"{\\\"backend_node_...</td>\n",
       "      <td>[{\"tag\": \"div\", \"attributes\": \"{\\\"backend_node...</td>\n",
       "      <td>united</td>\n",
       "      <td>Travel</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>401c4e6f-6b0b-47b4-8157-92d7ca468bbc</td>\n",
       "      <td>rent a car in Brooklyn - Central, NY on from A...</td>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>[[heading]  CAR -&gt; CLICK, [combobox]  Enter pi...</td>\n",
       "      <td>4</td>\n",
       "      <td>[button]  Sunday, April 9, 2023 -&gt; CLICK</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             action_uid  \\\n",
       "0  6c7a7082-2897-41c7-9688-4b0f3d778cdb   \n",
       "1  b64c2417-c44e-46c4-bb0b-ff1775e7da29   \n",
       "2  dad6690b-9b3e-4395-bd06-9aa065bf4027   \n",
       "3  e0fd3f28-3f04-455d-8bde-a480f0ec1b0a   \n",
       "4  4762d735-9dc2-4717-ae8b-baab0b3446e5   \n",
       "\n",
       "                                            raw_html  \\\n",
       "0  <!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.0 Tr...   \n",
       "1  <!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.0 Tr...   \n",
       "2  <!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.0 Tr...   \n",
       "3  <!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.0 Tr...   \n",
       "4  <!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.0 Tr...   \n",
       "\n",
       "                                        cleaned_html  \\\n",
       "0  <html backend_node_id=\"208\">\\n  <body backend_...   \n",
       "1  <html backend_node_id=\"10021\">\\n  <body backen...   \n",
       "2  <html backend_node_id=\"20041\">\\n  <body backen...   \n",
       "3  <html backend_node_id=\"30061\">\\n  <body backen...   \n",
       "4  <html backend_node_id=\"40453\">\\n  <body backen...   \n",
       "\n",
       "                                           operation  \\\n",
       "0  {\"original_op\": \"CLICK\", \"value\": \"\", \"op\": \"C...   \n",
       "1  {\"original_op\": \"TYPE\", \"value\": \"Brooklyn Cen...   \n",
       "2  {\"original_op\": \"CLICK\", \"value\": \"\", \"op\": \"C...   \n",
       "3  {\"original_op\": \"CLICK\", \"value\": \"\", \"op\": \"C...   \n",
       "4  {\"original_op\": \"CLICK\", \"value\": \"\", \"op\": \"C...   \n",
       "\n",
       "                                      pos_candidates  \\\n",
       "0  [{\"tag\": \"li\", \"attributes\": \"{\\\"backend_node_...   \n",
       "1  [{\"tag\": \"input\", \"attributes\": \"{\\\"backend_no...   \n",
       "2  [{\"tag\": \"button\", \"attributes\": \"{\\\"backend_n...   \n",
       "3  [{\"tag\": \"input\", \"attributes\": \"{\\\"backend_no...   \n",
       "4  [{\"tag\": \"td\", \"attributes\": \"{\\\"backend_node_...   \n",
       "\n",
       "                                      neg_candidates website  domain  \\\n",
       "0  [{\"tag\": \"div\", \"attributes\": \"{\\\"backend_node...  united  Travel   \n",
       "1  [{\"tag\": \"div\", \"attributes\": \"{\\\"backend_node...  united  Travel   \n",
       "2  [{\"tag\": \"div\", \"attributes\": \"{\\\"backend_node...  united  Travel   \n",
       "3  [{\"tag\": \"div\", \"attributes\": \"{\\\"backend_node...  united  Travel   \n",
       "4  [{\"tag\": \"div\", \"attributes\": \"{\\\"backend_node...  united  Travel   \n",
       "\n",
       "  subdomain                         annotation_id  \\\n",
       "0  Airlines  401c4e6f-6b0b-47b4-8157-92d7ca468bbc   \n",
       "1  Airlines  401c4e6f-6b0b-47b4-8157-92d7ca468bbc   \n",
       "2  Airlines  401c4e6f-6b0b-47b4-8157-92d7ca468bbc   \n",
       "3  Airlines  401c4e6f-6b0b-47b4-8157-92d7ca468bbc   \n",
       "4  Airlines  401c4e6f-6b0b-47b4-8157-92d7ca468bbc   \n",
       "\n",
       "                                      confirmed_task  \\\n",
       "0  rent a car in Brooklyn - Central, NY on from A...   \n",
       "1  rent a car in Brooklyn - Central, NY on from A...   \n",
       "2  rent a car in Brooklyn - Central, NY on from A...   \n",
       "3  rent a car in Brooklyn - Central, NY on from A...   \n",
       "4  rent a car in Brooklyn - Central, NY on from A...   \n",
       "\n",
       "                                          screenshot  \\\n",
       "0  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...   \n",
       "1  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...   \n",
       "2  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...   \n",
       "3  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...   \n",
       "4  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...   \n",
       "\n",
       "                                        action_reprs target_action_index  \\\n",
       "0  [[heading]  CAR -> CLICK, [combobox]  Enter pi...                   0   \n",
       "1  [[heading]  CAR -> CLICK, [combobox]  Enter pi...                   1   \n",
       "2  [[heading]  CAR -> CLICK, [combobox]  Enter pi...                   2   \n",
       "3  [[heading]  CAR -> CLICK, [combobox]  Enter pi...                   3   \n",
       "4  [[heading]  CAR -> CLICK, [combobox]  Enter pi...                   4   \n",
       "\n",
       "                                 target_action_reprs  action_id  \n",
       "0                            [heading]  CAR -> CLICK          0  \n",
       "1  [combobox]  Enter pick up city, airport name, ...          1  \n",
       "2  [div]  Brooklyn - Central (New York), US -> CLICK          2  \n",
       "3                         [textbox]  Pickup -> CLICK          3  \n",
       "4           [button]  Sunday, April 9, 2023 -> CLICK          4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the train split to a pandas DataFrame\n",
    "df = train_ds.to_pandas()\n",
    "df['action_id'] = range(len(df))  # Add a default integer ID column\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73519215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: rent a car in Brooklyn - Central, NY on from April 9 to April 15.\n",
      "step=1/7 | op={\"original_op\": \"CLICK\", \"value\": \"\", \"op\": \"CLICK\"} | target_action=[heading]  CAR -> CLICK | pos_candidates=1, action_id=0\n",
      "step=2/7 | op={\"original_op\": \"TYPE\", \"value\": \"Brooklyn Central\", \"op\": \"TYPE\"} | target_action=[combobox]  Enter pick up city, airport name, or airport code. -> TYPE: Brooklyn Central | pos_candidates=1, action_id=1\n",
      "step=3/7 | op={\"original_op\": \"CLICK\", \"value\": \"\", \"op\": \"CLICK\"} | target_action=[div]  Brooklyn - Central (New York), US -> CLICK | pos_candidates=1, action_id=2\n",
      "step=4/7 | op={\"original_op\": \"CLICK\", \"value\": \"\", \"op\": \"CLICK\"} | target_action=[textbox]  Pickup -> CLICK | pos_candidates=1, action_id=3\n",
      "step=5/7 | op={\"original_op\": \"CLICK\", \"value\": \"\", \"op\": \"CLICK\"} | target_action=[button]  Sunday, April 9, 2023 -> CLICK | pos_candidates=1, action_id=4\n",
      "step=6/7 | op={\"original_op\": \"CLICK\", \"value\": \"\", \"op\": \"CLICK\"} | target_action=[button]  Saturday, April 15, 2023 -> CLICK | pos_candidates=1, action_id=5\n",
      "step=7/7 | op={\"original_op\": \"CLICK\", \"value\": \"\", \"op\": \"CLICK\"} | target_action=[button]  Find cars button. -> CLICK | pos_candidates=1, action_id=6\n"
     ]
    }
   ],
   "source": [
    "# Group by annotation_id (this creates a GroupBy object for fast access)\n",
    "grouped = df.groupby('annotation_id')\n",
    "\n",
    "# Retrieve all rows for a specific annotation_id\n",
    "ann_id = train_ds[0][\"annotation_id\"]\n",
    "task_df = grouped.get_group(ann_id).sort_values('target_action_index')\n",
    "\n",
    "print(f\"Task: {task_df.iloc[0]['confirmed_task']}\")\n",
    "# Iterate and display (task_df is a DataFrame)\n",
    "for _, ex in task_df.iterrows():\n",
    "    print(\n",
    "        f\"step={int(ex['target_action_index']) + 1}/{len(task_df)} | op={ex['operation']} \"\n",
    "        f\"| target_action={ex[\"target_action_reprs\"]} | pos_candidates={len(ex['pos_candidates'])}, action_id={ex['action_id']}\"\n",
    "    )\n",
    "    # display(train_ds[ex[\"action_id\"]][\"screenshot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d5e8173",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dataloader'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m sys.path.append(\u001b[33m'\u001b[39m\u001b[33m./Mind2Web/src\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcandidate_generation\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataloader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CandidateRankDataset, get_data_split\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcandidate_generation\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CERerankingEvaluator\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcandidate_generation\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/project/Robots-That-Ask-For-Help-Over-The-Horizon/Mind2Web/src/candidate_generation/metric.py:12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlxml\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdataloader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m format_candidate\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlxml\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m etree\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'dataloader'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add Mind2Web to path so we can import from it\n",
    "sys.path.append('./Mind2Web/src')\n",
    "\n",
    "from candidate_generation.dataloader import CandidateRankDataset, get_data_split\n",
    "from candidate_generation.metric import CERerankingEvaluator\n",
    "from candidate_generation.model import CrossEncoder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "eval_data = train_ds\n",
    "batch_size = 350\n",
    "max_seq_length = 512\n",
    "\n",
    "eval_evaluator = CERerankingEvaluator(\n",
    "    eval_data,\n",
    "    k=50,\n",
    "    max_neg=-1,\n",
    "    batch_size=batch_size,\n",
    "    name=\"train\",\n",
    ")\n",
    "\n",
    "# Use the model path for the CrossEncoder (like in evaluate.py)\n",
    "model_path = \"osunlp/MindAct_CandidateGeneration_deberta-v3-base\"\n",
    "model = CrossEncoder(\n",
    "    model_path,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    num_labels=1,\n",
    "    max_length=max_seq_length,\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Running evaluation...\")\n",
    "eval_evaluator(model, output_path=\"./output\")\n",
    "print(\"Evaluation completed!\")\n",
    "print(\"Results saved to: ./output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a3762560",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.read_pickle('scores_all_data.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f042422a",
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = task_df.iloc[0][\"annotation_id\"]\n",
    "a_uid, a_id = list(scores[\"scores\"].keys())[0].split('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d270851",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mscores\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mscores\u001b[39m\u001b[33m\"\u001b[39m].keys())[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'scores' is not defined"
     ]
    }
   ],
   "source": [
    "list(scores[\"scores\"].keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ad599d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action_uid</th>\n",
       "      <th>raw_html</th>\n",
       "      <th>cleaned_html</th>\n",
       "      <th>operation</th>\n",
       "      <th>pos_candidates</th>\n",
       "      <th>neg_candidates</th>\n",
       "      <th>website</th>\n",
       "      <th>domain</th>\n",
       "      <th>subdomain</th>\n",
       "      <th>annotation_id</th>\n",
       "      <th>confirmed_task</th>\n",
       "      <th>screenshot</th>\n",
       "      <th>action_reprs</th>\n",
       "      <th>target_action_index</th>\n",
       "      <th>target_action_reprs</th>\n",
       "      <th>action_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [action_uid, raw_html, cleaned_html, operation, pos_candidates, neg_candidates, website, domain, subdomain, annotation_id, confirmed_task, screenshot, action_reprs, target_action_index, target_action_reprs, action_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['annotation_id'].str.startswith(\"15486e7c\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b56b16e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html = task_df.iloc[0][\"cleaned_html\"]\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "def get_element_html(node_id: str):\n",
    "    el = soup.find(attrs={\"backend_node_id\": node_id})\n",
    "    return str(el) if el is not None else None\n",
    "\n",
    "# Example: show HTML for the top-1 candidate\n",
    "best_id = task_df.iloc[0][\"pos_candidates\"][0]\n",
    "print(get_element_html(best_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465dad02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Download the MindAct Candidate Generation model\n",
    "print(\"Downloading MindAct Candidate Generation model...\")\n",
    "model_name = \"osunlp/MindAct_CandidateGeneration_deberta-v3-base\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=CACHE_DIR)\n",
    "\n",
    "# Load model\n",
    "candidate_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=CACHE_DIR,\n",
    "    torch_dtype=torch.float16,  # Use float16 for efficiency\n",
    "    device_map=\"auto\"  # Automatically handle device placement\n",
    ")\n",
    "\n",
    "print(f\"Model {model_name} downloaded and loaded successfully!\")\n",
    "print(f\"Model type: {type(candidate_model)}\")\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in candidate_model.parameters()):,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
