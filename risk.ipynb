{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ab0c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "SLURM_PATH = '/home/yandex/MLWG2025/amitr5'\n",
    "CACHE_DIR = '' \n",
    "\n",
    "if SLURM_PATH in os.getcwd():\n",
    "        CACHE_DIR = f'{SLURM_PATH}/tmp/hf_cache' \n",
    "        os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "        os.environ[\"PIP_PATH\"] = f\"{SLURM_PATH}/BaryGNN/anaconda3/envs/conf/bin/pip\"\n",
    "        os.environ[\"TEMP_DIR\"] = CACHE_DIR\n",
    "        os.environ[\"HF_HOME\"] = CACHE_DIR\n",
    "        os.environ[\"TRANSFORMERS_CACHE\"] = CACHE_DIR\n",
    "        os.environ[\"HF_DATASETS_CACHE\"] = CACHE_DIR\n",
    "        # Hugging Face uses HUGGINGFACE_HUB_CACHE (HF_HUB_CACHE is ignored)\n",
    "        os.environ[\"HUGGINGFACE_HUB_CACHE\"] = CACHE_DIR\n",
    "        os.environ[\"TMPDIR\"] = CACHE_DIR\n",
    "        os.environ[\"XDG_CACHE_HOME\"] = CACHE_DIR\n",
    "        # os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Imports #\n",
    "import numpy as np\n",
    "from transformers import Qwen3VLForConditionalGeneration, AutoProcessor, AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "# from datasets import load_dataset\n",
    "# import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "# Project imports #\n",
    "\n",
    "import utils\n",
    "from mind2web.dataloader import build_datasets_dict, subsample_by_annotation ,MultiChoiceDataset\n",
    "from utils import CACHE_DIR\n",
    "from utils import log_response\n",
    "# sys.path.append('./Mind2Web/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f98e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.reload('mind2web.dataloader')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-xl\", cache_dir=CACHE_DIR)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"osunlp/MindAct_ActionPrediction_flan-t5-xl\"\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, cache_dir=CACHE_DIR, device_map=\"auto\")\n",
    "model.eval();\n",
    "\n",
    "\n",
    "idx_split_map = {0:\"test_task\", 1:\"test_domain\", 2:\"test_website\"}\n",
    "split_idx_map = {v:k for k,v in idx_split_map.items()}\n",
    "ds_dict = build_datasets_dict(idx_split_map.values(),cache_dir=CACHE_DIR);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed098d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.reload('mind2web.dataloader')\n",
    "from mind2web.dataloader import subsample_by_annotation, MultiChoiceDataset\n",
    "cal_dict, test_dict = {}, {}\n",
    "seed = 42\n",
    "frac = 0.1\n",
    "num_candidates=5\n",
    "max_context_len=512\n",
    "\n",
    "for split, ds in ds_dict.items():\n",
    "    flattened = ds_dict[split]\n",
    "    cal_set, test_set = subsample_by_annotation(flattened, frac=frac, seed=seed)\n",
    "    cal_dict[split] = MultiChoiceDataset(\n",
    "        cal_set, tokenizer, num_candidates=num_candidates, max_context_len=max_context_len, cache_prompt=True, cache_tokenized=True\n",
    "    )\n",
    "    test_dict[split] = MultiChoiceDataset(\n",
    "        test_set, tokenizer, num_candidates=num_candidates, max_context_len=max_context_len,cache_prompt=True, cache_tokenized=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c0c7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_threshold(scores, alpha: float):\n",
    "    N = len(scores)\n",
    "    k = int(np.ceil((N + 1) * (1 - alpha)))\n",
    "    sorted_scores = np.sort(scores.values)\n",
    "    threshold = sorted_scores[k - 1]\n",
    "    return threshold\n",
    "\n",
    "\n",
    "cal_df = pd.read_pickle(\"cal_results.pkl\")\n",
    "test_df = pd.read_pickle(\"test_results.pkl\")\n",
    "cal_df['correct'] = cal_df['pred_label'] == cal_df['label']\n",
    "cal_df['true_prob'] = cal_df.apply(lambda row: row['choices_probs'][row['label']] if row['label'] in row['choices_probs'] else 0, axis=1)\n",
    "\n",
    "# google's nonconformity score\n",
    "cal_grouped = cal_df.groupby('annotation_id')\n",
    "score_per_group = 1 - cal_grouped['true_prob'].min()\n",
    "\n",
    "threshold = get_threshold(score_per_group, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2741e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
