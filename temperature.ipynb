{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39ab0c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "SLURM_PATH = '/home/yandex/MLWG2025/amitr5'\n",
    "CACHE_DIR = '' \n",
    "\n",
    "if SLURM_PATH in os.getcwd():\n",
    "        CACHE_DIR = f'{SLURM_PATH}/tmp/hf_cache' \n",
    "        os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "        os.environ[\"PIP_PATH\"] = f\"{SLURM_PATH}/BaryGNN/anaconda3/envs/conf/bin/pip\"\n",
    "        os.environ[\"TEMP_DIR\"] = CACHE_DIR\n",
    "        os.environ[\"HF_HOME\"] = CACHE_DIR\n",
    "        os.environ[\"TRANSFORMERS_CACHE\"] = CACHE_DIR\n",
    "        os.environ[\"HF_DATASETS_CACHE\"] = CACHE_DIR\n",
    "        # Hugging Face uses HUGGINGFACE_HUB_CACHE (HF_HUB_CACHE is ignored)\n",
    "        os.environ[\"HUGGINGFACE_HUB_CACHE\"] = CACHE_DIR\n",
    "        os.environ[\"TMPDIR\"] = CACHE_DIR\n",
    "        os.environ[\"XDG_CACHE_HOME\"] = CACHE_DIR\n",
    "        # os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Imports #\n",
    "import numpy as np\n",
    "# from transformers import Qwen3VLForConditionalGeneration, AutoProcessor, AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "# from datasets import load_dataset\n",
    "# import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "# Project imports #\n",
    "\n",
    "import utils\n",
    "from mind2web.dataloader import build_datasets_dict, subsample_by_annotation ,MultiChoiceDataset, MultiChoiceDatasetRandom, MultiChoiceDatasetPrompt, raw_data_collate_fn\n",
    "from utils import CACHE_DIR\n",
    "from utils import log_response\n",
    "from utils.llm import get_wrapper, collect_prompt_predictions\n",
    "\n",
    "# sys.path.append('./Mind2Web/src')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aa863a",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b745eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d334d181b6e344349a738a8c49f9e86a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02379bfc6b46438c87b06c69604261ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aff0eb16c47f4f43859e5338b2113e29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fcc3512247248f7b43bf1e7b81b3238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing split: test_task\n",
      "Processing split: test_domain\n",
      "Processing split: test_website\n"
     ]
    }
   ],
   "source": [
    "from utils.prompts import get_prompt_template\n",
    "from utils.llm import BaseWrapper\n",
    "\n",
    "model = get_wrapper(\"Qwen\")\n",
    "ds_dict = build_datasets_dict(cache_dir=CACHE_DIR);\n",
    "datasets = {}\n",
    "for split, test_split in ds_dict.items():\n",
    "    print(f\"Processing split: {split}\")\n",
    "    datasets[split] = MultiChoiceDatasetPrompt(\n",
    "        test_split, prompt_template=get_prompt_template('mind2web_with_context'), num_candidates=5, split_name=split, add_screenshot=False\n",
    "    )\n",
    "records_df = collect_prompt_predictions(model, datasets, batch_size=1)\n",
    "records_df.to_pickle('Qwen_answers.pkl')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916cb01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation_id</th>\n",
       "      <th>action_uid</th>\n",
       "      <th>pred_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>choices_logits</th>\n",
       "      <th>test_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91695df8-f256-47c9-8c37-06e8d0fc758f</td>\n",
       "      <td>73e0e7ed-d784-4b7a-a06c-48324e44ce7b</td>\n",
       "      <td>Answer: B.\\nAction: CLICK</td>\n",
       "      <td>B.\\nAction: CLICK\\n</td>\n",
       "      <td>{'A': 31.78125, 'B': 29.421875, 'C': 23.859375...</td>\n",
       "      <td>test_task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>277e3468-f8cb-45c6-9e4b-0328066c42d3</td>\n",
       "      <td>6584ac66-77f3-4b4f-878f-604d8c93ba48</td>\n",
       "      <td>Answer: A. None of the above</td>\n",
       "      <td>B.\\nAction: CLICK\\n</td>\n",
       "      <td>{'A': 38.1875, 'B': 25.703125, 'C': 21.109375,...</td>\n",
       "      <td>test_domain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>013781df-4391-4533-bcb1-15f6819064f6</td>\n",
       "      <td>79c4a963-4aa9-49c1-9257-6b0d5069c551</td>\n",
       "      <td>Answer: A. None of the above</td>\n",
       "      <td>B.\\nAction: CLICK\\n</td>\n",
       "      <td>{'A': 33.28125, 'B': 24.421875, 'C': 22.796875...</td>\n",
       "      <td>test_website</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          annotation_id                            action_uid  \\\n",
       "0  91695df8-f256-47c9-8c37-06e8d0fc758f  73e0e7ed-d784-4b7a-a06c-48324e44ce7b   \n",
       "1  277e3468-f8cb-45c6-9e4b-0328066c42d3  6584ac66-77f3-4b4f-878f-604d8c93ba48   \n",
       "2  013781df-4391-4533-bcb1-15f6819064f6  79c4a963-4aa9-49c1-9257-6b0d5069c551   \n",
       "\n",
       "                      pred_text          target_text  \\\n",
       "0     Answer: B.\\nAction: CLICK  B.\\nAction: CLICK\\n   \n",
       "1  Answer: A. None of the above  B.\\nAction: CLICK\\n   \n",
       "2  Answer: A. None of the above  B.\\nAction: CLICK\\n   \n",
       "\n",
       "                                      choices_logits    test_split  \n",
       "0  {'A': 31.78125, 'B': 29.421875, 'C': 23.859375...     test_task  \n",
       "1  {'A': 38.1875, 'B': 25.703125, 'C': 21.109375,...   test_domain  \n",
       "2  {'A': 33.28125, 'B': 24.421875, 'C': 22.796875...  test_website  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle('answers/Qwen_answers_backup.pkl')\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6bb9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utils.llm- reloaded\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d4a532e80047a8a07e88fbb2a0f478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-xl\", cache_dir=CACHE_DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958f5f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mind2web- reloaded\n",
      "mind2web.dataloader- reloaded\n"
     ]
    }
   ],
   "source": [
    "utils.reload('mind2web', 'mind2web.dataloader')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7208a2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3518"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "# del model\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0571a182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mind2web- reloaded\n",
      "mind2web.dataloader- reloaded\n",
      "utils.prompts- reloaded\n",
      "utils.llm- reloaded\n",
      "Processing split: test_task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/transformers/generation/utils.py:2532: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target Text:\n",
      "B.\n",
      "Action: SELECT\n",
      "Value: 02 30 PM\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.reload('mind2web', 'mind2web.dataloader', 'utils.prompts', 'utils.llm')\n",
    "from utils.prompts import get_prompt_template\n",
    "\n",
    "x = 5\n",
    "\n",
    "for split in data_dict.keys():\n",
    "    print(f\"Processing split: {split}\")\n",
    "    data_dict[split].prompt_template = get_prompt_template('mind2web_with_context')\n",
    "    for i, samp in enumerate(data_dict[split]):\n",
    "        if i != x: continue\n",
    "        prompt = samp['prompt']\n",
    "        output = model.generate([prompt])\n",
    "        break\n",
    "    break\n",
    "# print(\"Prompt:\")\n",
    "# print(samp['prompt'])\n",
    "# print(\"-------------\")\n",
    "print(\"\\nTarget Text:\")\n",
    "print(samp['target_text'])\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1d556b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mind2web- reloaded\n",
      "mind2web.dataloader- reloaded\n",
      "utils.prompts- reloaded\n",
      "utils.llm- reloaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'pred_text': 'Answer: B.\\nAction: SELECT\\nValue: 02:30 pm',\n",
       "  'choices_logits': {'A': 21.390625,\n",
       "   'B': 31.546875,\n",
       "   'C': 24.96875,\n",
       "   'D': 25.75,\n",
       "   'E': 19.578125,\n",
       "   'F': 16.9375}}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.reload('mind2web', 'mind2web.dataloader', 'utils.prompts', 'utils.llm')\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afed4c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing split: test_task\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 360.00 MiB. GPU 1 has a total capacity of 11.90 GiB of which 300.62 MiB is free. Process 291357 has 3.12 GiB memory in use. Including non-PyTorch memory, this process has 8.48 GiB memory in use. Of the allocated memory 8.16 GiB is allocated by PyTorch, and 153.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[76]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[32m     13\u001b[39m     \u001b[38;5;66;03m# if i != x: continue\u001b[39;00m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == x:\u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     batch_records = \u001b[43mgenerate_batch_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     all_records.extend(batch_records)\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m# break\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/project/Robots-That-Ask-For-Help-Over-The-Horizon/utils/llm.py:810\u001b[39m, in \u001b[36mgenerate_batch_records\u001b[39m\u001b[34m(model, batch, split_name, temperature, shrinkage)\u001b[39m\n\u001b[32m    808\u001b[39m prompts = batch[\u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    809\u001b[39m images = batch.get(\u001b[33m\"\u001b[39m\u001b[33mscreenshot_image\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m810\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    812\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerated \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(outputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m records for split \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    813\u001b[39m \u001b[38;5;28mprint\u001b[39m(outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/project/Robots-That-Ask-For-Help-Over-The-Horizon/utils/llm.py:462\u001b[39m, in \u001b[36mMultimodalCausalWrapper.generate\u001b[39m\u001b[34m(self, prompts, images, **kwargs)\u001b[39m\n\u001b[32m    454\u001b[39m inputs = \u001b[38;5;28mself\u001b[39m.processor(\n\u001b[32m    455\u001b[39m     text=text_prompts,\n\u001b[32m    456\u001b[39m     images=images \u001b[38;5;28;01mif\u001b[39;00m images \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    457\u001b[39m     padding=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    458\u001b[39m     return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    459\u001b[39m ).to(\u001b[38;5;28mself\u001b[39m.model.device)\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.inference_mode():\n\u001b[32m--> \u001b[39m\u001b[32m462\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[38;5;66;03m# Slice off the prompt portion\u001b[39;00m\n\u001b[32m    472\u001b[39m input_len = inputs.input_ids.shape[\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/transformers/generation/utils.py:2564\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2561\u001b[39m model_kwargs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = generation_config.use_cache\n\u001b[32m   2563\u001b[39m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2564\u001b[39m result = \u001b[43mdecoding_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2565\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2566\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2568\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2570\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgeneration_mode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2571\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2572\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2574\u001b[39m \u001b[38;5;66;03m# Convert to legacy cache format if requested\u001b[39;00m\n\u001b[32m   2575\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2576\u001b[39m     generation_config.return_legacy_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   2577\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2578\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(result.past_key_values, \u001b[33m\"\u001b[39m\u001b[33mto_legacy_cache\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2579\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/transformers/generation/utils.py:2784\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   2781\u001b[39m model_inputs = \u001b[38;5;28mself\u001b[39m.prepare_inputs_for_generation(input_ids, **model_kwargs)\n\u001b[32m   2783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[32m-> \u001b[39m\u001b[32m2784\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   2785\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   2786\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/accelerate/hooks.py:175\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/transformers/utils/generic.py:1064\u001b[39m, in \u001b[36mcheck_model_inputs.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1061\u001b[39m                 monkey_patched_layers.append((module, original_forward))\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1064\u001b[39m     outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m original_exception:\n\u001b[32m   1066\u001b[39m     \u001b[38;5;66;03m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[39;00m\n\u001b[32m   1067\u001b[39m     \u001b[38;5;66;03m# Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\u001b[39;00m\n\u001b[32m   1068\u001b[39m     \u001b[38;5;66;03m# Otherwise -> we're probably missing `**kwargs` in the decorated function\u001b[39;00m\n\u001b[32m   1069\u001b[39m     kwargs_without_recordable = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recordable_keys}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/transformers/models/qwen3_vl/modeling_qwen3_vl.py:1344\u001b[39m, in \u001b[36mQwen3VLForConditionalGeneration.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, pixel_values, pixel_values_videos, image_grid_thw, video_grid_thw, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m   1314\u001b[39m \u001b[38;5;129m@check_model_inputs\u001b[39m\n\u001b[32m   1315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m   1316\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1329\u001b[39m     **kwargs: Unpack[TransformersKwargs],\n\u001b[32m   1330\u001b[39m ) -> Union[\u001b[38;5;28mtuple\u001b[39m, Qwen3VLCausalLMOutputWithPast]:\n\u001b[32m   1331\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1332\u001b[39m \u001b[33;03m    labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[32m   1333\u001b[39m \u001b[33;03m        Labels for computing the masked language modeling loss. Indices should either be in `[0, ...,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1342\u001b[39m \u001b[33;03m        TODO: Add example\u001b[39;00m\n\u001b[32m   1343\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1344\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1345\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1346\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1347\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpixel_values_videos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpixel_values_videos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1348\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimage_grid_thw\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimage_grid_thw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1349\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvideo_grid_thw\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvideo_grid_thw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1350\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1351\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1352\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1353\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1354\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1355\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1356\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1358\u001b[39m     hidden_states = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1360\u001b[39m     \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/transformers/utils/generic.py:1064\u001b[39m, in \u001b[36mcheck_model_inputs.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1061\u001b[39m                 monkey_patched_layers.append((module, original_forward))\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1064\u001b[39m     outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m original_exception:\n\u001b[32m   1066\u001b[39m     \u001b[38;5;66;03m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[39;00m\n\u001b[32m   1067\u001b[39m     \u001b[38;5;66;03m# Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\u001b[39;00m\n\u001b[32m   1068\u001b[39m     \u001b[38;5;66;03m# Otherwise -> we're probably missing `**kwargs` in the decorated function\u001b[39;00m\n\u001b[32m   1069\u001b[39m     kwargs_without_recordable = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recordable_keys}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/transformers/models/qwen3_vl/modeling_qwen3_vl.py:1223\u001b[39m, in \u001b[36mQwen3VLModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, pixel_values, pixel_values_videos, image_grid_thw, video_grid_thw, cache_position, **kwargs)\u001b[39m\n\u001b[32m   1220\u001b[39m         position_ids = position_ids.add(delta)\n\u001b[32m   1221\u001b[39m         position_ids = position_ids.unsqueeze(\u001b[32m0\u001b[39m).expand(\u001b[32m3\u001b[39m, -\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1223\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlanguage_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1225\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1226\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1227\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1228\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1229\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1230\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvisual_pos_masks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvisual_pos_masks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1231\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdeepstack_visual_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeepstack_visual_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1232\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Qwen3VLModelOutputWithPast(\n\u001b[32m   1236\u001b[39m     last_hidden_state=outputs.last_hidden_state,\n\u001b[32m   1237\u001b[39m     past_key_values=outputs.past_key_values,\n\u001b[32m   1238\u001b[39m     rope_deltas=\u001b[38;5;28mself\u001b[39m.rope_deltas,\n\u001b[32m   1239\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/transformers/utils/generic.py:1064\u001b[39m, in \u001b[36mcheck_model_inputs.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1061\u001b[39m                 monkey_patched_layers.append((module, original_forward))\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1064\u001b[39m     outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m original_exception:\n\u001b[32m   1066\u001b[39m     \u001b[38;5;66;03m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[39;00m\n\u001b[32m   1067\u001b[39m     \u001b[38;5;66;03m# Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\u001b[39;00m\n\u001b[32m   1068\u001b[39m     \u001b[38;5;66;03m# Otherwise -> we're probably missing `**kwargs` in the decorated function\u001b[39;00m\n\u001b[32m   1069\u001b[39m     kwargs_without_recordable = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recordable_keys}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/transformers/models/qwen3_vl/modeling_qwen3_vl.py:850\u001b[39m, in \u001b[36mQwen3VLTextModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, visual_pos_masks, deepstack_visual_embeds, **kwargs)\u001b[39m\n\u001b[32m    848\u001b[39m \u001b[38;5;66;03m# decoder layers\u001b[39;00m\n\u001b[32m    849\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer_idx, decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.layers):\n\u001b[32m--> \u001b[39m\u001b[32m850\u001b[39m     layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_position_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    855\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    859\u001b[39m     hidden_states = layer_outputs\n\u001b[32m    861\u001b[39m     \u001b[38;5;66;03m# add visual features to the hidden states of first several layers\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/transformers/modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/accelerate/hooks.py:175\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/transformers/models/qwen3_vl/modeling_qwen3_vl.py:502\u001b[39m, in \u001b[36mQwen3VLTextDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, position_embeddings, attention_mask, position_ids, past_key_values, use_cache, cache_position, **kwargs)\u001b[39m\n\u001b[32m    500\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.input_layernorm(hidden_states)\n\u001b[32m    501\u001b[39m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m502\u001b[39m hidden_states, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    512\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    514\u001b[39m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/accelerate/hooks.py:175\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/transformers/models/qwen3_vl/modeling_qwen3_vl.py:444\u001b[39m, in \u001b[36mQwen3VLTextAttention.forward\u001b[39m\u001b[34m(self, hidden_states, position_embeddings, attention_mask, past_key_values, cache_position, **kwargs)\u001b[39m\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config._attn_implementation != \u001b[33m\"\u001b[39m\u001b[33meager\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    442\u001b[39m     attention_interface = ALL_ATTENTION_FUNCTIONS[\u001b[38;5;28mself\u001b[39m.config._attn_implementation]\n\u001b[32m--> \u001b[39m\u001b[32m444\u001b[39m attn_output, attn_weights = \u001b[43mattention_interface\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    446\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    448\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    449\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    450\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention_dropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    455\u001b[39m attn_output = attn_output.reshape(*input_shape, -\u001b[32m1\u001b[39m).contiguous()\n\u001b[32m    456\u001b[39m attn_output = \u001b[38;5;28mself\u001b[39m.o_proj(attn_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/transformers/integrations/sdpa_attention.py:96\u001b[39m, in \u001b[36msdpa_attention_forward\u001b[39m\u001b[34m(module, query, key, value, attention_mask, dropout, scaling, is_causal, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m attention_mask.dtype != torch.bool:\n\u001b[32m     93\u001b[39m         \u001b[38;5;66;03m# Convert to boolean type, making sdpa to force call FlashAttentionScore to improve performance.\u001b[39;00m\n\u001b[32m     94\u001b[39m         attention_mask = torch.logical_not(attention_mask.bool()).to(query.device)\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m attn_output = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msdpa_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m attn_output = attn_output.transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m).contiguous()\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 360.00 MiB. GPU 1 has a total capacity of 11.90 GiB of which 300.62 MiB is free. Process 291357 has 3.12 GiB memory in use. Including non-PyTorch memory, this process has 8.48 GiB memory in use. Of the allocated memory 8.16 GiB is allocated by PyTorch, and 153.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43474fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds_dict = build_datasets_dict(cache_dir=CACHE_DIR);\n",
    "seed = 42\n",
    "frac = 0.2\n",
    "num_candidates=5\n",
    "max_context_len=512\n",
    "data_dict = {}\n",
    "# for split, test_split in ds_dict.items():\n",
    "    # data_dict[split] = MultiChoiceDataset(\n",
    "    #     ds_dict, tokenizer, num_candidates=num_candidates, max_context_len=max_context_len, cache_prompt=True, cache_tokenized=True\n",
    "    # )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ce7f71be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'annotation_id': '91695df8-f256-47c9-8c37-06e8d0fc758f',\n",
       " 'action_uid': 'ea2865e4-2858-478c-bf83-93d576cad774',\n",
       " 'output_text': 'Answer: B.\\nAction: CLICK',\n",
       " 'target_text': 'B.\\nAction: CLICK\\n',\n",
       " 'choices_logits': {'A': 32.90625,\n",
       "  'B': 31.171875,\n",
       "  'C': 23.390625,\n",
       "  'D': 22.984375,\n",
       "  'E': 17.640625,\n",
       "  'F': 17.984375},\n",
       " 'test_split': 'test_task'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_records[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "608c2055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fef55597ba04cc6862535edb9f1326e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "# del model\n",
    "# from utils.llm_utils import get_wrapper\n",
    "# model = get_wrapper(\"Qwen/Qwen3-VL-8B-Instruct\", cache_dir=CACHE_DIR)\n",
    "model_name = \"Qwen/Qwen3-VL-8B-Instruct\"\n",
    "processor = AutoProcessor.from_pretrained(model_name, cache_dir=CACHE_DIR)\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=CACHE_DIR,\n",
    "    dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78318778",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-xl\", cache_dir=CACHE_DIR)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"osunlp/MindAct_ActionPrediction_flan-t5-xl\"\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, cache_dir=CACHE_DIR, device_map=\"auto\")\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e2f82b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utils.prompts- reloaded\n"
     ]
    }
   ],
   "source": [
    "utils.reload('utils.prompts')\n",
    "from utils.prompts import get_prompt_template\n",
    "tokenizer = processor.tokenizer\n",
    "prompt_template = get_prompt_template('mind2web')\n",
    "for split, test_split in ds_dict.items():\n",
    "    data_dict[split] = MultiChoiceDatasetPrompt(\n",
    "        ds_dict[split], tokenizer, prompt_template=prompt_template, num_candidates=num_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed098d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mind2web.dataloader- reloaded\n"
     ]
    }
   ],
   "source": [
    "utils.reload('mind2web.dataloader')\n",
    "\n",
    "ds_dict = build_datasets_dict(MultiChoiceDataset.id2split.values(),cache_dir=CACHE_DIR);\n",
    "data_dict, rnd_data_dict = {}, {} \n",
    "seed = 42\n",
    "frac = 0.2\n",
    "num_candidates=5\n",
    "max_context_len=512\n",
    "\n",
    "for split, test_split in ds_dict.items():\n",
    "    data_dict[split] = MultiChoiceDataset(\n",
    "        test_split, tokenizer, num_candidates=num_candidates, max_context_len=max_context_len, cache_prompt=True, cache_tokenized=True\n",
    "    )\n",
    "    rnd_data_dict[split] = MultiChoiceDatasetRandom(\n",
    "        test_split, tokenizer, num_candidates=num_candidates, max_context_len=max_context_len, top_k=10, neg_ratio=0.05\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8d9686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utils.helpers- reloaded\n",
      "utils.llm_utils- reloaded\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544667fa56194e9d82c778ba2cf64ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 610.00 MiB. GPU 0 has a total capacity of 11.90 GiB of which 202.88 MiB is free. Including non-PyTorch memory, this process has 11.69 GiB memory in use. Of the allocated memory 11.42 GiB is allocated by PyTorch, and 107.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     25\u001b[39m df_list = []\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m split_name, ds_split \u001b[38;5;129;01min\u001b[39;00m tqdm(test_dict.items()):\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     df = \u001b[43mrun_split_random\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds_split\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     df_list.append(df)\n\u001b[32m     30\u001b[39m results_df = pd.concat(df_list, ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mrun_split_random\u001b[39m\u001b[34m(split_name, ds, model, tokenizer, batch_size, num_iterations, temperature)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# ds.seed = rand_idx\u001b[39;00m\n\u001b[32m     16\u001b[39m loader = DataLoader(ds, batch_size=batch_size, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers=\u001b[32m0\u001b[39m, collate_fn=mind2web.dataloader.multichoice_collate_fn)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m results = \u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m records = pd.DataFrame(results)\n\u001b[32m     19\u001b[39m records[\u001b[33m'\u001b[39m\u001b[33mrand_idx\u001b[39m\u001b[33m'\u001b[39m] = rand_idx\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/project/Robots-That-Ask-For-Help-Over-The-Horizon/utils/llm_utils.py:620\u001b[39m, in \u001b[36mbatch_generate\u001b[39m\u001b[34m(model, tokenizer, loader, split_name, temperature)\u001b[39m\n\u001b[32m    618\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[32m    619\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.inference_mode():\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m         out = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    621\u001b[39m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minput_ids\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mattention_mask\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    623\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[43m            \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m            \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    629\u001b[39m         out_texts = tokenizer.batch_decode(out[\u001b[33m\"\u001b[39m\u001b[33msequences\u001b[39m\u001b[33m\"\u001b[39m], skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    631\u001b[39m         \u001b[38;5;66;03m# Labels may contain ignore_index (-100); replace with pad id before decoding\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/transformers/generation/utils.py:2465\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2461\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m`attention_mask` passed to `generate` must be 2D.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2463\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoder_outputs\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[32m   2464\u001b[39m     \u001b[38;5;66;03m# if model is encoder decoder encoder_outputs are created and added to `model_kwargs`\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2465\u001b[39m     model_kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_encoder_decoder_kwargs_for_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2466\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_input_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_config\u001b[49m\n\u001b[32m   2467\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2469\u001b[39m \u001b[38;5;66;03m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[32m   2470\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/transformers/generation/utils.py:861\u001b[39m, in \u001b[36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[39m\u001b[34m(self, inputs_tensor, model_kwargs, model_input_name, generation_config)\u001b[39m\n\u001b[32m    859\u001b[39m encoder_kwargs[\u001b[33m\"\u001b[39m\u001b[33mreturn_dict\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    860\u001b[39m encoder_kwargs[model_input_name] = inputs_tensor\n\u001b[32m--> \u001b[39m\u001b[32m861\u001b[39m model_kwargs[\u001b[33m\"\u001b[39m\u001b[33mencoder_outputs\u001b[39m\u001b[33m\"\u001b[39m]: ModelOutput = \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mencoder_kwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    863\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model_kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/accelerate/hooks.py:175\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/transformers/models/t5/modeling_t5.py:1100\u001b[39m, in \u001b[36mT5Stack.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m   1097\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m   1098\u001b[39m     all_hidden_states = all_hidden_states + (hidden_states,)\n\u001b[32m-> \u001b[39m\u001b[32m1100\u001b[39m layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1103\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[32m   1107\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1113\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1116\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1118\u001b[39m \u001b[38;5;66;03m# We share the position biases between the layers - the first layer store them\u001b[39;00m\n\u001b[32m   1119\u001b[39m \u001b[38;5;66;03m# layer_outputs = hidden-states, key-value-states (self-attention position bias), (self-attention weights),\u001b[39;00m\n\u001b[32m   1120\u001b[39m \u001b[38;5;66;03m# (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/transformers/modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/accelerate/hooks.py:175\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/transformers/models/t5/modeling_t5.py:687\u001b[39m, in \u001b[36mT5Block.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_values, use_cache, output_attentions, return_dict, cache_position)\u001b[39m\n\u001b[32m    670\u001b[39m \u001b[38;5;129m@deprecate_kwarg\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mpast_key_value\u001b[39m\u001b[33m\"\u001b[39m, new_name=\u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m, version=\u001b[33m\"\u001b[39m\u001b[33m4.58\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    671\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    672\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    685\u001b[39m     cache_position=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    686\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m687\u001b[39m     self_attention_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    697\u001b[39m     hidden_states = self_attention_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    698\u001b[39m     attention_outputs = self_attention_outputs[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/accelerate/hooks.py:175\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/transformers/models/t5/modeling_t5.py:603\u001b[39m, in \u001b[36mT5LayerSelfAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_values, use_cache, output_attentions, cache_position)\u001b[39m\n\u001b[32m    590\u001b[39m \u001b[38;5;129m@deprecate_kwarg\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mpast_key_value\u001b[39m\u001b[33m\"\u001b[39m, new_name=\u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m, version=\u001b[33m\"\u001b[39m\u001b[33m4.58\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    592\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    600\u001b[39m     cache_position=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    601\u001b[39m ):\n\u001b[32m    602\u001b[39m     normed_hidden_states = \u001b[38;5;28mself\u001b[39m.layer_norm(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m603\u001b[39m     attention_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mSelfAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    604\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnormed_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    608\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    609\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    610\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    611\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    612\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    613\u001b[39m     hidden_states = hidden_states + \u001b[38;5;28mself\u001b[39m.dropout(attention_output[\u001b[32m0\u001b[39m])\n\u001b[32m    614\u001b[39m     outputs = (hidden_states,) + attention_output[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/accelerate/hooks.py:175\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/yandex/MLWG2025/amitr5/BaryGNN/anaconda3/envs/conf/lib/python3.13/site-packages/transformers/models/t5/modeling_t5.py:549\u001b[39m, in \u001b[36mT5Attention.forward\u001b[39m\u001b[34m(self, hidden_states, mask, key_value_states, position_bias, past_key_values, layer_head_mask, query_length, use_cache, output_attentions, cache_position)\u001b[39m\n\u001b[32m    547\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    548\u001b[39m         causal_mask = mask[:, :, :, : key_states.shape[-\u001b[32m2\u001b[39m]]\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m         position_bias = \u001b[43mposition_bias\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mcausal_mask\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pruned_heads:\n\u001b[32m    552\u001b[39m     mask = torch.ones(position_bias.shape[\u001b[32m1\u001b[39m])\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 610.00 MiB. GPU 0 has a total capacity of 11.90 GiB of which 202.88 MiB is free. Including non-PyTorch memory, this process has 11.69 GiB memory in use. Of the allocated memory 11.42 GiB is allocated by PyTorch, and 107.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "utils.reload('utils.helpers','utils.llm_utils')\n",
    "import pandas as pd\n",
    "import gc\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import mind2web\n",
    "\n",
    "\n",
    "def run_split_random(split_name, ds, model, tokenizer, batch_size=7, num_iterations=5, temperature=1):\n",
    "    all_records  = []\n",
    "    for rand_idx in range(num_iterations):\n",
    "        # Clear GPU memory before next iteration\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        if isinstance(ds, MultiChoiceDatasetRandom):\n",
    "            ds.seed = rand_idx\n",
    "        loader = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=mind2web.dataloader.multichoice_collate_fn)\n",
    "        results = utils.llm.batch_generate(model, tokenizer, loader, split_name=split_name, temperature=temperature)\n",
    "        records = pd.DataFrame(results)\n",
    "        \n",
    "        if not isinstance(ds, MultiChoiceDatasetRandom):\n",
    "            records['rand_idx'] = -1\n",
    "        else:\n",
    "            records['rand_idx'] = rand_idx\n",
    "        all_records.append(records)\n",
    "\n",
    "    final_df = pd.concat(all_records, ignore_index=True)\n",
    "    return final_df\n",
    "\n",
    "df_list = []\n",
    "for split_name, ds_split in tqdm(rnd_data_dict.items()):\n",
    "    df = run_split_random(split_name, ds_split, model, tokenizer, temperature=6)\n",
    "    df_list.append(df)\n",
    "\n",
    "results_df = pd.concat(df_list, ignore_index=True)\n",
    "results_df.to_pickle(\"rnd_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "4c5999df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relative_idx</th>\n",
       "      <th>annotation_id</th>\n",
       "      <th>action_uid</th>\n",
       "      <th>output_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>choices_logits</th>\n",
       "      <th>test_split</th>\n",
       "      <th>rand_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0572899e-7c07-4a2f-a77b-bba4f432a7ad</td>\n",
       "      <td>7194e8bf-6cf3-4f36-a37f-70fd065c4aac</td>\n",
       "      <td>C. Action: CLICK</td>\n",
       "      <td>C. Action: CLICK</td>\n",
       "      <td>{'A': -3.084818124771118, 'B': -5.401023387908...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0572899e-7c07-4a2f-a77b-bba4f432a7ad</td>\n",
       "      <td>aa34483b-ad90-4054-b38b-d29157a1c517</td>\n",
       "      <td>B. Action: CLICK</td>\n",
       "      <td>B. Action: CLICK</td>\n",
       "      <td>{'A': 0.7131706476211548, 'B': 6.4016227722167...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0572899e-7c07-4a2f-a77b-bba4f432a7ad</td>\n",
       "      <td>49b0e49e-deab-4400-987a-4cfd6ba09a84</td>\n",
       "      <td>D. Action: CLICK</td>\n",
       "      <td>D. Action: CLICK</td>\n",
       "      <td>{'A': 0.5229284763336182, 'B': -3.964406251907...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0572899e-7c07-4a2f-a77b-bba4f432a7ad</td>\n",
       "      <td>aa40812d-f178-4d28-b6de-6ec9ca1b2758</td>\n",
       "      <td>B. Action: TYPE Value: SFTBAO</td>\n",
       "      <td>B. Action: TYPE Value: SFTBAO</td>\n",
       "      <td>{'A': -1.5480059385299683, 'B': 6.001170635223...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0572899e-7c07-4a2f-a77b-bba4f432a7ad</td>\n",
       "      <td>998b187b-44a3-4f3d-93de-e00fdd23e4cf</td>\n",
       "      <td>B. Action: TYPE Value: Joe</td>\n",
       "      <td>B. Action: TYPE Value: Joe</td>\n",
       "      <td>{'A': -0.452083945274353, 'B': 5.8127889633178...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   relative_idx                         annotation_id  \\\n",
       "0             0  0572899e-7c07-4a2f-a77b-bba4f432a7ad   \n",
       "1             1  0572899e-7c07-4a2f-a77b-bba4f432a7ad   \n",
       "2             2  0572899e-7c07-4a2f-a77b-bba4f432a7ad   \n",
       "3             3  0572899e-7c07-4a2f-a77b-bba4f432a7ad   \n",
       "4             4  0572899e-7c07-4a2f-a77b-bba4f432a7ad   \n",
       "\n",
       "                             action_uid                    output_text  \\\n",
       "0  7194e8bf-6cf3-4f36-a37f-70fd065c4aac              C. Action: CLICK    \n",
       "1  aa34483b-ad90-4054-b38b-d29157a1c517              B. Action: CLICK    \n",
       "2  49b0e49e-deab-4400-987a-4cfd6ba09a84              D. Action: CLICK    \n",
       "3  aa40812d-f178-4d28-b6de-6ec9ca1b2758  B. Action: TYPE Value: SFTBAO   \n",
       "4  998b187b-44a3-4f3d-93de-e00fdd23e4cf     B. Action: TYPE Value: Joe   \n",
       "\n",
       "                     target_text  \\\n",
       "0              C. Action: CLICK    \n",
       "1              B. Action: CLICK    \n",
       "2              D. Action: CLICK    \n",
       "3  B. Action: TYPE Value: SFTBAO   \n",
       "4     B. Action: TYPE Value: Joe   \n",
       "\n",
       "                                      choices_logits  test_split  rand_idx  \n",
       "0  {'A': -3.084818124771118, 'B': -5.401023387908...           0         0  \n",
       "1  {'A': 0.7131706476211548, 'B': 6.4016227722167...           0         0  \n",
       "2  {'A': 0.5229284763336182, 'B': -3.964406251907...           0         0  \n",
       "3  {'A': -1.5480059385299683, 'B': 6.001170635223...           0         0  \n",
       "4  {'A': -0.452083945274353, 'B': 5.8127889633178...           0         0  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c29d35d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utils.helpers- reloaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      {'A': 0.139629527926445, 'B': 0.09491278976202...\n",
       "1      {'A': 0.18216946721076965, 'B': 0.470131605863...\n",
       "2      {'A': 0.18113406002521515, 'B': 0.085742481052...\n",
       "3      {'A': 0.1509549766778946, 'B': 0.5312207937240...\n",
       "4      {'A': 0.17022627592086792, 'B': 0.483607709407...\n",
       "                             ...                        \n",
       "105    {'A': 0.15855087339878082, 'B': 0.075187072157...\n",
       "106    {'A': 0.2257235050201416, 'B': 0.4127052128314...\n",
       "107    {'A': 0.17477934062480927, 'B': 0.491915583610...\n",
       "108    {'A': 0.13793626427650452, 'B': 0.560035169124...\n",
       "109    {'A': 0.3012753427028656, 'B': 0.1248216852545...\n",
       "Name: choices_probs, Length: 110, dtype: object"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.reload('utils.helpers')\n",
    "results_df['choices_probs'] = results_df['choices_logits'].apply(lambda x: (utils.helpers.choices_softmax(x, temperature=6.0)))\n",
    "results_df['choices_probs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "7ce1a16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relative_idx</th>\n",
       "      <th>annotation_id</th>\n",
       "      <th>action_uid</th>\n",
       "      <th>output_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>choices_probs</th>\n",
       "      <th>test_split</th>\n",
       "      <th>rand_idx</th>\n",
       "      <th>target_label</th>\n",
       "      <th>target_action</th>\n",
       "      <th>target_value</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_action</th>\n",
       "      <th>pred_value</th>\n",
       "      <th>correct</th>\n",
       "      <th>true_prob</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0572899e-7c07-4a2f-a77b-bba4f432a7ad</td>\n",
       "      <td>7194e8bf-6cf3-4f36-a37f-70fd065c4aac</td>\n",
       "      <td>C. Action: CLICK</td>\n",
       "      <td>C. Action: CLICK</td>\n",
       "      <td>{'A': 0.139629527926445, 'B': 0.09491277486085...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>CLICK</td>\n",
       "      <td>None</td>\n",
       "      <td>C</td>\n",
       "      <td>CLICK</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.556245</td>\n",
       "      <td>0.556245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0572899e-7c07-4a2f-a77b-bba4f432a7ad</td>\n",
       "      <td>aa34483b-ad90-4054-b38b-d29157a1c517</td>\n",
       "      <td>B. Action: CLICK</td>\n",
       "      <td>B. Action: CLICK</td>\n",
       "      <td>{'A': 0.18216946721076965, 'B': 0.470131665468...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>CLICK</td>\n",
       "      <td>None</td>\n",
       "      <td>B</td>\n",
       "      <td>CLICK</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.470132</td>\n",
       "      <td>0.470132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0572899e-7c07-4a2f-a77b-bba4f432a7ad</td>\n",
       "      <td>49b0e49e-deab-4400-987a-4cfd6ba09a84</td>\n",
       "      <td>D. Action: CLICK</td>\n",
       "      <td>D. Action: CLICK</td>\n",
       "      <td>{'A': 0.18113403022289276, 'B': 0.085742458701...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>CLICK</td>\n",
       "      <td>None</td>\n",
       "      <td>D</td>\n",
       "      <td>CLICK</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.461323</td>\n",
       "      <td>0.461323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0572899e-7c07-4a2f-a77b-bba4f432a7ad</td>\n",
       "      <td>aa40812d-f178-4d28-b6de-6ec9ca1b2758</td>\n",
       "      <td>B. Action: TYPE Value: SFTBAO</td>\n",
       "      <td>B. Action: TYPE Value: SFTBAO</td>\n",
       "      <td>{'A': 0.1509549766778946, 'B': 0.5312207341194...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>TYPE</td>\n",
       "      <td>SFTBAO</td>\n",
       "      <td>B</td>\n",
       "      <td>TYPE</td>\n",
       "      <td>SFTBAO</td>\n",
       "      <td>True</td>\n",
       "      <td>0.531221</td>\n",
       "      <td>0.531221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0572899e-7c07-4a2f-a77b-bba4f432a7ad</td>\n",
       "      <td>998b187b-44a3-4f3d-93de-e00fdd23e4cf</td>\n",
       "      <td>B. Action: TYPE Value: Joe</td>\n",
       "      <td>B. Action: TYPE Value: Joe</td>\n",
       "      <td>{'A': 0.17022626101970673, 'B': 0.483607649803...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>TYPE</td>\n",
       "      <td>Joe</td>\n",
       "      <td>B</td>\n",
       "      <td>TYPE</td>\n",
       "      <td>Joe</td>\n",
       "      <td>True</td>\n",
       "      <td>0.483608</td>\n",
       "      <td>0.483608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   relative_idx                         annotation_id  \\\n",
       "0             0  0572899e-7c07-4a2f-a77b-bba4f432a7ad   \n",
       "1             1  0572899e-7c07-4a2f-a77b-bba4f432a7ad   \n",
       "2             2  0572899e-7c07-4a2f-a77b-bba4f432a7ad   \n",
       "3             3  0572899e-7c07-4a2f-a77b-bba4f432a7ad   \n",
       "4             4  0572899e-7c07-4a2f-a77b-bba4f432a7ad   \n",
       "\n",
       "                             action_uid                    output_text  \\\n",
       "0  7194e8bf-6cf3-4f36-a37f-70fd065c4aac              C. Action: CLICK    \n",
       "1  aa34483b-ad90-4054-b38b-d29157a1c517              B. Action: CLICK    \n",
       "2  49b0e49e-deab-4400-987a-4cfd6ba09a84              D. Action: CLICK    \n",
       "3  aa40812d-f178-4d28-b6de-6ec9ca1b2758  B. Action: TYPE Value: SFTBAO   \n",
       "4  998b187b-44a3-4f3d-93de-e00fdd23e4cf     B. Action: TYPE Value: Joe   \n",
       "\n",
       "                     target_text  \\\n",
       "0              C. Action: CLICK    \n",
       "1              B. Action: CLICK    \n",
       "2              D. Action: CLICK    \n",
       "3  B. Action: TYPE Value: SFTBAO   \n",
       "4     B. Action: TYPE Value: Joe   \n",
       "\n",
       "                                       choices_probs  test_split  rand_idx  \\\n",
       "0  {'A': 0.139629527926445, 'B': 0.09491277486085...           0         0   \n",
       "1  {'A': 0.18216946721076965, 'B': 0.470131665468...           0         0   \n",
       "2  {'A': 0.18113403022289276, 'B': 0.085742458701...           0         0   \n",
       "3  {'A': 0.1509549766778946, 'B': 0.5312207341194...           0         0   \n",
       "4  {'A': 0.17022626101970673, 'B': 0.483607649803...           0         0   \n",
       "\n",
       "  target_label target_action target_value pred_label pred_action pred_value  \\\n",
       "0            C         CLICK         None          C       CLICK       None   \n",
       "1            B         CLICK         None          B       CLICK       None   \n",
       "2            D         CLICK         None          D       CLICK       None   \n",
       "3            B          TYPE       SFTBAO          B        TYPE     SFTBAO   \n",
       "4            B          TYPE          Joe          B        TYPE        Joe   \n",
       "\n",
       "   correct  true_prob  pred_prob  \n",
       "0     True   0.556245   0.556245  \n",
       "1     True   0.470132   0.470132  \n",
       "2     True   0.461323   0.461323  \n",
       "3     True   0.531221   0.531221  \n",
       "4     True   0.483608   0.483608  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c0c7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utils.helpers- reloaded\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cal_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      8\u001b[39m utils.reload(\u001b[33m'\u001b[39m\u001b[33mutils.helpers\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# cal_df = pd.read_pickle(\"cal_results.pkl\")\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# test_df = pd.read_pickle(\"test_results.pkl\")\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# cal_df = utils.helpers.add_eval_columns(results_df)\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# cal_df['correct'] = cal_df['pred_label'] == cal_df['label']\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# cal_df['true_prob'] = cal_df.apply(lambda row: row['choices_probs'][row['label']] if row['label'] in row['choices_probs'] else 0, axis=1)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m cal_df[\u001b[33m'\u001b[39m\u001b[33mchoices_probs\u001b[39m\u001b[33m'\u001b[39m] = utils.helpers.softmax_with_temperature_from_probs(\u001b[43mcal_df\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mchoices_probs\u001b[39m\u001b[33m'\u001b[39m], temperature=\u001b[32m6.0\u001b[39m)\n\u001b[32m     18\u001b[39m cal_df[\u001b[33m'\u001b[39m\u001b[33mtrue_prob\u001b[39m\u001b[33m'\u001b[39m] = cal_df.apply(\u001b[38;5;28;01mlambda\u001b[39;00m row: row[\u001b[33m'\u001b[39m\u001b[33mchoices_probs\u001b[39m\u001b[33m'\u001b[39m][row[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m]] \u001b[38;5;28;01mif\u001b[39;00m row[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m row[\u001b[33m'\u001b[39m\u001b[33mchoices_probs\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m, axis=\u001b[32m1\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# google's nonconformity score\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'cal_df' is not defined"
     ]
    }
   ],
   "source": [
    "def get_threshold(scores, alpha: float):\n",
    "    N = len(scores)\n",
    "    k = int(np.ceil((N + 1) * (1 - alpha)))\n",
    "    sorted_scores = np.sort(scores.values)\n",
    "    threshold = sorted_scores[k - 1]\n",
    "    return threshold\n",
    "\n",
    "utils.reload('utils.helpers')\n",
    "\n",
    "# cal_df = pd.read_pickle(\"cal_results.pkl\")\n",
    "# test_df = pd.read_pickle(\"test_results.pkl\")\n",
    "# cal_df = utils.helpers.add_eval_columns(results_df)\n",
    "# cal_df['correct'] = cal_df['pred_label'] == cal_df['label']\n",
    "# cal_df['true_prob'] = cal_df.apply(lambda row: row['choices_probs'][row['label']] if row['label'] in row['choices_probs'] else 0, axis=1)\n",
    "\n",
    "\n",
    "cal_df['choices_probs'] = utils.helpers.softmax_with_temperature_from_probs(cal_df['choices_probs'], temperature=6.0)\n",
    "cal_df['true_prob'] = cal_df.apply(lambda row: row['choices_probs'][row['label']] if row['label'] in row['choices_probs'] else 0, axis=1)\n",
    "# google's nonconformity score\n",
    "cal_grouped = cal_grouped = cal_df.groupby(['annotation_id','rand_idx'])\n",
    "score_per_group = 1 - cal_grouped['true_prob'].min()\n",
    "\n",
    "threshold = get_threshold(score_per_group, alpha=0.1)\n",
    "test_df = pd.read_pickle(\"test_results.pkl\")\n",
    "# test_df = utils.helpers.add_eval_columns(test_df, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "6ef4932f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average pred_set size: 2.09346439041214, Median size: 2.0, Prop of 1> : 0.9413692015864804\n",
      "0.9270563890325918\n"
     ]
    }
   ],
   "source": [
    "print(f'Average pred_set size: {test_df[\"pred_set_size\"].mean()}, Median size: {test_df[\"pred_set_size\"].median()}, Prop of 1> : {np.mean(test_df['pred_set_size'] > 1)}')\n",
    "true_in_pred = test_df.apply(lambda row: row['label'] in row['pred_set'], axis=1).mean()\n",
    "print(true_in_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "67335c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average pred_set size: 2.469908604931885, Median size: 2.0, Prop of 1> : 0.991722710812209\n",
      "0.9696499396447663\n"
     ]
    }
   ],
   "source": [
    "print(f'Average pred_set size: {test_df[\"pred_set_size\"].mean()}, Median size: {test_df[\"pred_set_size\"].median()}, Prop of 1> : {np.mean(test_df['pred_set_size'] > 1)}')\n",
    "true_in_pred = test_df.apply(lambda row: row['label'] in row['pred_set'], axis=1).mean()\n",
    "print(true_in_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "2888353e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average pred_set size: 2.3091912398689427, Median size: 2.0, Prop of 1> : 0.9806863252284876\n",
      "0.9574064493878255\n"
     ]
    }
   ],
   "source": [
    "print(f'Average pred_set size: {test_df[\"pred_set_size\"].mean()}, Median size: {test_df[\"pred_set_size\"].median()}, Prop of 1> : {np.mean(test_df['pred_set_size'] > 1)}')\n",
    "true_in_pred = test_df.apply(lambda row: row['label'] in row['pred_set'], axis=1).mean()\n",
    "print(true_in_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "53c24484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average pred_set size: 2.4098982583204003, Median size: 2.0, Prop of 1> : 0.9877565097430592\n",
      "prop 0.9648, new threshold: 0.8889, diff:0.0000\n"
     ]
    }
   ],
   "source": [
    "x=score_per_group.reset_index()\n",
    "mask = (x[\"rand_idx\"]==9)\n",
    "\n",
    "y = get_threshold(x[mask]['true_prob'], alpha=0.1)\n",
    "pred_set = test_df['choices_probs'].apply(lambda row: [ label for label, prob in row.items() if 1 - prob <= y])\n",
    "pred_set_size = pred_set.apply(len)\n",
    "\n",
    "print(f'Average pred_set size: {pred_set_size.mean()}, Median size: {pred_set_size.median()}, Prop of 1> : {np.mean(pred_set_size > 1)}')\n",
    "test_df['naive_pred_set'] = pred_set\n",
    "true_in_pred = test_df.apply(lambda row: row['label'] in row['naive_pred_set'], axis=1).mean()\n",
    "print(f'prop {true_in_pred:.4f}, new threshold: {y:.4f}, diff:{y - threshold:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e146a4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_pickle('test_results.pkl')\n",
    "x[\"pred_set\"] = x['choices_probs'].apply(lambda row: [ label for label, prob in row.items() if 1 - prob <= 0.9998])\n",
    "x[\"pred_set_size\"] = x[\"pred_set\"].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343f4f50",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da4da92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "utils.reload('utils.helpers')\n",
    "\n",
    "cal_df = pd.read_pickle('cal_df.pkl')\n",
    "cal_df = utils.helpers.add_eval_columns(cal_df)\n",
    "label_map = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3, \"E\": 4, \"F\": 5}\n",
    "y_cal = cal_df[\"target_label\"].map(label_map)\n",
    "\n",
    "alpha = 0.05\n",
    "lambda_grid = np.linspace(0.0, 1.0, 1000)\n",
    "\n",
    "best_lambda, results = utils.helpers.tune_lambda_group_risk(\n",
    "    cal_df=cal_df,\n",
    "    y_cal=y_cal,\n",
    "    alpha=alpha,\n",
    "    lambda_grid=lambda_grid,\n",
    ")\n",
    "\n",
    "best = results[best_lambda]\n",
    "best, best_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898a2242",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alpha =  1-best_lambda\n",
    "logits = cal_df['choices_logits'].apply(lambda x: list(x.values()))\n",
    "logits = np.array(logits.tolist()).reshape(-1, 6) # 6 = A,.., F\n",
    "logits += np.abs(logits.min(axis=1).reshape(-1,1))\n",
    "logits[:,0] = logits[:,0] * (alpha)\n",
    "\n",
    "preds_raw = logits.argmax(axis=1) + 65\n",
    "preds = [chr(x) for x in preds_raw]\n",
    "\n",
    "preds_df = pd.DataFrame(preds, columns=['pred'])\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(6,4))\n",
    "cal_df['target_label'].hist(alpha=0.5, label='Ground Truth', )\n",
    "preds_df['pred'].hist(alpha=0.7, label='Reweighted preds', )\n",
    "cal_df['pred_label'].hist(alpha=0.5, label='Original preds',)\n",
    "plt.title(rf'Label distribution ($\\lambda = {1-best_lambda:.4f}$)')\n",
    "plt.legend()\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54ce6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_df = pd.read_pickle('pen_df.pkl')\n",
    "pen_df = utils.helpers.add_eval_columns(pen_df)\n",
    "logits = pen_df['choices_logits'].apply(lambda x: list(x.values()))\n",
    "logits = np.array(logits.tolist()).reshape(-1, 6) # 6 = A,.., F\n",
    "logits += np.abs(logits.min(axis=1).reshape(-1,1))\n",
    "logits[:,0] = logits[:,0] * (1-best_lambda) #(1 - 0.84)\n",
    "\n",
    "preds_raw = logits.argmax(axis=1) + 65\n",
    "preds = [chr(x) for x in preds_raw]\n",
    "print((preds == pen_df['target_label']).mean())\n",
    "print(pen_df['correct'].mean())\n",
    "\n",
    "\n",
    "preds_df = pd.DataFrame(preds, columns=['pred'])\n",
    "preds_df['correct'] = (preds_df['pred'] == pen_df['target_label'])\n",
    "preds_df[preds_df['correct'] == False].value_counts()\n",
    "\n",
    "\n",
    "pen_df['target_label'].hist(alpha=0.5, label='Ground Truth')\n",
    "preds_df['pred'].hist(alpha=0.7, label='Reweighted preds')\n",
    "pen_df['pred_label'].hist(alpha=0.5, label='original pred')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.title(rf'Label distribution ($\\lambda = {1-best_lambda:.4f}$)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa94020e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
